---
title: 虚拟内存——与物理内存建立映射：页
categories:
  - 笔记
tags:
  - 默认标签
toc: true
comments: true
description: ''
date: 2025-12-05 18:18:55
author: 土土
updated:
---
为了更好地共享同一块物理内存的数据 & 简化编程模型，**虚拟内存（Virtual Memory）** 应运而生。  
虚拟内存为每个进程提供独立、连续、逻辑统一的地址空间。实际访问发生在物理内存 + 磁盘之间，由操作系统自动管理。
本篇笔记记录虚拟内存的体系结构、地址翻译过程与优化机制。

<!-- more -->

# 与物理内存建立映射：页
概念上，内存是一块连续字节数组，为了方便访问和存储，把地址空间进行层级划分：

- 把虚拟内存划分为若干大小为 P 字节的块，称为虚拟页（VP）
- 物理页（PP）或页帧，同理。

实际上的访问操作仍在物理内存上进行，所以需要对虚拟内存和物理内存建立映射，这个过程称为 **地址翻译** 。

## 虚拟页的生命周期
在任意时刻，一个进程的虚拟地址空间中的所有虚拟页（VP）可以被划分为三个不相交的子集。

- 未分配 = VM系统还未分配（或创建）的页。未分配的块没有数据与之关联，因此不占用任何磁盘空间。
- 分配 = 虚拟地址与磁盘上的物理地址建立映射
  - 未缓存 → 缺页（page fault），选择牺牲页（按需页面调度，本篇笔记称为按需加载）。数据存储在磁盘上的 **交换空间（Swap Space）** 中。
  - 缓存 = 磁盘上的数据（物理页）加载到主存。

> ### 虚拟内存的高效性
> * 按需分配：程序启动时未分配。第一次访问一个虚拟地址时才分配。
> * 按需加载：程序启动时不加载代码页，只在第一次访问时（读/写）才通过 page fault 加载。
>
> 虚拟内存到磁盘的访问是昂贵的，因此  
  DRAM 全相联 → 操作系统可以自由选择把某个虚拟页扔到任何物理页框里  
>  （组相联只能同组，更严苛是一一映射）  
    （因为可以自由选择物理页框，OS 就能使用最优的页面替换算法，把最“冷”的虚拟页换出去，让最“热”的工作集留在 DRAM 中，从而避免大量昂贵的磁盘访问）。
>
> 由于局部性原理，昂贵的磁盘访问 + 按需加载最终是高效的。

## 地址翻译
虚拟地址在传送到主存前经过 **MMU（memory manage unit）** 翻译成物理地址。

- 页表 = PTE（page table entry，页表条目）的数组
- PTE  = valid bits + 物理地址（主存 or 磁盘）/下一级页表PTE位置
- 虚拟地址 = VPN + VPO，其中 VPN 是页表中 PTE 的位置。
  - VPN = TLBT + TLBI
  - VPN = VPN1 + VPN2 + ···
- 物理地址 = PPN + VPO
  - PPN = CT
  - PPO = CI + CO
- PTBR（page table base register）指向内存中的页表，本身位于cpu中。

**流程**：
1. CPU 产生虚拟地址 VA，MMU 先访问TLB，不命中则进行页表遍历。使用 PTBR 指向的基地址，通过 VPN 访问 L1 中缓存的页表条目，一级级直到内存中的页表。若不命中，在磁盘中加载物理页到主存中使 PTE 合法，重新启动指令。
2. 此过程中 `PPO = VPO` 恒成立，一开始就将其取出并在 Cache 中查找 PA，直到返回 CT 进行检查。

> ### 安全性  
> 可以方便地在 PTE 中增加许可位来实现对内存访问的限制。违反将会触发段错误（segmentation fault）。

### 优化：
1. 在高速缓存中缓存页表条目；
2. MMU 内置 TLB, TLBT + TLBI = VPN（若TLB 有 2^t 个组，TLBI 就为 t 位）
3. 多级页表（只有一级页表才需要在主存中，二级可以根据虚拟内存创建或是持空，只有最常使用的才缓存在主存中）对应 VPN 被分成多块。由于 TLB，访问多级页表的开销可承受。

> 注意：高速缓存 Cache 访问通常用 **物理地址** 而不是虚拟地址，因为这样能避免多进程共享同一物理页时带来的冲突，也能避免权限检查在 Cache 前额外处理。使用物理地址更简单、安全、通用。